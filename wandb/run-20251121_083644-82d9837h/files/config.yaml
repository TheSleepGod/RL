_wandb:
    value:
        cli_version: 0.22.2
        e:
            73l1q5x56whz004xifc079h393lystev:
                args:
                    - --config
                    - configs/ppo_qwen2_7b.yaml
                codePath: rl/train_ppo.py
                codePathLocal: rl/train_ppo.py
                cpu_count: 64
                cpu_count_logical: 128
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "134146424832"
                        used: "56423874560"
                email: 1634504737@qq.com
                executable: /usr/bin/python3
                git:
                    commit: 27478aaf747598cca154530016472f135138897f
                gpu: NVIDIA A100-SXM4-80GB
                gpu_count: 2
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-90ebae2a-d22f-7555-dc98-62614dd0ef64
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-403db92a-cd5e-881c-f998-49ef37fdd61c
                host: trial-17281668-trialrun-17281621-worker-0
                memory:
                    total: "2163865071616"
                os: Linux-5.4.210.bsk.6-amd64-x86_64-with-glibc2.36
                program: /mnt/bn/search-nlp-us/haohanwen/haohw/rl/train_ppo.py
                python: CPython 3.11.2
                root: /mnt/bn/search-nlp-us/haohanwen/haohw
                startedAt: "2025-11-21T08:36:44.420395Z"
                writerId: 73l1q5x56whz004xifc079h393lystev
        m: []
        python_version: 3.11.2
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 84
                - 98
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 84
                - 98
            "3":
                - 13
                - 16
            "4": 3.11.2
            "5": 0.22.2
            "6": 4.57.1
            "12": 0.22.2
            "13": linux-x86_64
base_model_path:
    value: /opt/tiger/model/Qwen2-7B
data:
    value:
        include_system: false
        max_prompt_len: 512
        path: data/ppo_prompts.jsonl
        response_template: |
            ### 助手
loss:
    value:
        kwargs:
            alpha: 0.5
        name: calibrated
model:
    value:
        attn_impl: flash_attention_2
        base_model_path: /opt/tiger/model/Qwen2-7B
        lora_adapter_path: out/sft_qwen2_7b/final
        torch_dtype: bf16
ppo:
    value:
        batch_size: 32
        gamma: 1
        gradient_accumulation_steps: 4
        lam: 0.95
        learning_rate: 1e-05
        mini_batch_size: 8
seed:
    value: 42
sft_adapter_path:
    value: out/sft_qwen2_7b/final
train:
    value:
        logging_steps: 10
        num_epochs: 2
        output_dir: out/ppo_model
        report_to: wandb
        save_steps: 100
        wandb_project: rlhf-confidence-debug
trainer:
    value:
        adap_kl_ctrl: true
        clip_epsilon: 0.2
        init_kl_coef: 0.1
        target_kl: 6
        use_score_norm: false
        use_score_scaling: false
